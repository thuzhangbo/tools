# PCDN vs Normal Traffic Classification using Decision Tree
# ä½¿ç”¨ ip.proto å’Œ tcp.srcport ç‰¹å¾è¿›è¡Œå†³ç­–æ ‘äºŒåˆ†ç±»
#
# ğŸš€ æ•°æ®ç¼“å­˜åŠŸèƒ½è¯´æ˜:
# - é¦–æ¬¡è¿è¡Œ: åŠ è½½åŸå§‹CSVæ•°æ®ï¼Œé¢„å¤„ç†åè‡ªåŠ¨ä¿å­˜åˆ°ç¼“å­˜
# - åç»­è¿è¡Œ: è‡ªåŠ¨æ£€æµ‹å¹¶åŠ è½½ç¼“å­˜æ•°æ®ï¼Œå¤§å¹…æå‡å¯åŠ¨é€Ÿåº¦
# - å¼ºåˆ¶é‡æ–°åŠ è½½: å°†ä¸‹æ–¹ force_reload è®¾ç½®ä¸º True
# - ç¼“å­˜ä½ç½®: data_cache/preprocessed_data.pkl

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, accuracy_score, precision_recall_curve, f1_score, precision_score, recall_score
from sklearn.preprocessing import StandardScaler
import os
import glob
import pickle
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False

# è®¾ç½®å›¾è¡¨æ ·å¼
try:
    plt.style.use('seaborn-v0_8')
except:
    plt.style.use('default')
sns.set_palette("husl")

print("ğŸŒ³ å¼€å§‹PCDNæµé‡å†³ç­–æ ‘åˆ†ç±»ä»»åŠ¡")
print("ğŸ“‹ ä½¿ç”¨ç‰¹å¾: ip.proto, tcp.srcport")
print("ğŸ¯ æ¨¡å‹: Decision Tree Classifier")
print("=" * 60)

# å®šä¹‰æ•°æ®è·¯å¾„
base_path = "pcdn_32pkts_2class_feature_enhance_v14.5_dataset"
train_path = os.path.join(base_path, "Training_set")
val_path = os.path.join(base_path, "Validation_set") 
test_path = os.path.join(base_path, "Testing_set")

# é€‰æ‹©çš„ç‰¹å¾
selected_features = ['tcp.dstport', 'udp.dstport', 'tcp.srcport', 'udp.srcport']

# æ•°æ®ç¼“å­˜è®¾ç½®
cache_dir = "data_cache"
cache_file = os.path.join(cache_dir, "preprocessed_data.pkl")
force_reload = True  # è®¾ç½®ä¸ºTrueå¼ºåˆ¶é‡æ–°åŠ è½½æ•°æ®

def load_data_from_directory(directory_path, label):
    """åŠ è½½æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰CSVæ–‡ä»¶"""
    csv_files = glob.glob(os.path.join(directory_path, "*.csv"))
    dataframes = []
    
    for file in csv_files:
        try:
            df = pd.read_csv(file)
            df['label'] = label  # æ·»åŠ æ ‡ç­¾
            df['source_file'] = os.path.basename(file)  # è®°å½•æ¥æºæ–‡ä»¶
            dataframes.append(df)
            print(f"âœ… åŠ è½½æ–‡ä»¶: {file} (æ ·æœ¬æ•°: {len(df)})")
        except Exception as e:
            print(f"âŒ åŠ è½½æ–‡ä»¶å¤±è´¥: {file}, é”™è¯¯: {e}")
    
    if dataframes:
        combined_df = pd.concat(dataframes, ignore_index=True)
        print(f"ğŸ“Š {directory_path} æ€»æ ·æœ¬æ•°: {len(combined_df)}")
        return combined_df
    else:
        print(f"âš ï¸  {directory_path} æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆæ•°æ®")
        return pd.DataFrame()

# æ£€æŸ¥æ˜¯å¦æœ‰ç©ºçš„æ•°æ®é›†
def safe_concat(dataframes, set_name):
    """å®‰å…¨åˆå¹¶æ•°æ®é›†ï¼Œå¤„ç†ç©ºæ•°æ®é›†çš„æƒ…å†µ"""
    non_empty_dfs = [df for df in dataframes if not df.empty]
    if not non_empty_dfs:
        print(f"âš ï¸  {set_name} æ²¡æœ‰æœ‰æ•ˆæ•°æ®!")
        return pd.DataFrame()
    return pd.concat(non_empty_dfs, ignore_index=True)

def preprocess_features(data, features):
    """é¢„å¤„ç†ç‰¹å¾æ•°æ®"""
    processed_data = data.copy()
    
    # æ£€æŸ¥ç‰¹å¾æ˜¯å¦å­˜åœ¨
    missing_features = [f for f in features if f not in processed_data.columns]
    if missing_features:
        print(f"âš ï¸  ç¼ºå¤±ç‰¹å¾: {missing_features}")
        return None
    
    # æå–é€‰æ‹©çš„ç‰¹å¾
    feature_data = processed_data[features].copy()
    
    # å¤„ç†ç¼ºå¤±å€¼
    print(f"ğŸ“Š ç‰¹å¾ç¼ºå¤±å€¼ç»Ÿè®¡:")
    for feature in features:
        missing_count = feature_data[feature].isna().sum()
        print(f"  {feature}: {missing_count} ä¸ªç¼ºå¤±å€¼")
        
        # å¯¹äºæ•°å€¼å‹ç‰¹å¾ï¼Œç”¨ä¸­ä½æ•°å¡«å……ç¼ºå¤±å€¼
        if missing_count > 0:
            median_val = feature_data[feature].median()
            if pd.isna(median_val):  # å¦‚æœä¸­ä½æ•°ä¹Ÿæ˜¯NaNï¼ˆå…¨éƒ¨éƒ½æ˜¯ç¼ºå¤±å€¼ï¼‰
                # ä½¿ç”¨0å¡«å……æˆ–è€…ç‰¹å¾çš„å…¸å‹å€¼
                if feature == 'ip.proto':
                    fill_val = 6  # TCPåè®®
                elif feature == 'tcp.srcport':
                    fill_val = 0  # é»˜è®¤ç«¯å£
                else:
                    fill_val = 0  # é€šç”¨é»˜è®¤å€¼
                print(f"    ç‰¹å¾å…¨éƒ¨ç¼ºå¤±ï¼Œä½¿ç”¨é»˜è®¤å€¼ {fill_val} å¡«å……")
            else:
                fill_val = median_val
                print(f"    å·²ç”¨ä¸­ä½æ•° {fill_val} å¡«å……")
            
            feature_data[feature].fillna(fill_val, inplace=True)
    
    return feature_data

# æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç¼“å­˜æ•°æ®
if not force_reload and os.path.exists(cache_file):
    print(f"\nğŸš€ å‘ç°ç¼“å­˜æ•°æ®ï¼Œæ­£åœ¨å¿«é€ŸåŠ è½½...")
    try:
        with open(cache_file, 'rb') as f:
            cached_data = pickle.load(f)
        
        X_train_scaled = cached_data['X_train_scaled']
        X_val_scaled = cached_data['X_val_scaled']  
        X_test_scaled = cached_data['X_test_scaled']
        y_train = cached_data['y_train']
        y_val = cached_data['y_val']
        y_test = cached_data['y_test']
        scaler = cached_data['scaler']
        
        # ä»ç¼“å­˜ä¸­æ¢å¤åŸå§‹ç‰¹å¾æ•°æ®ï¼ˆç”¨äºåç»­ç»Ÿè®¡ï¼‰
        X_train = X_train_scaled  # å¯¹äºæ˜¾ç¤ºç›®çš„ï¼Œä½¿ç”¨scaledç‰ˆæœ¬
        X_val = X_val_scaled
        X_test = X_test_scaled
        
        print(f"âœ… ç¼“å­˜æ•°æ®åŠ è½½æˆåŠŸ!")
        print(f"ğŸ“Š è®­ç»ƒé›†: {X_train_scaled.shape[0]} æ ·æœ¬, {X_train_scaled.shape[1]} ç‰¹å¾")
        print(f"ğŸ“Š éªŒè¯é›†: {X_val_scaled.shape[0]} æ ·æœ¬")
        print(f"ğŸ“Š æµ‹è¯•é›†: {X_test_scaled.shape[0]} æ ·æœ¬")
        print(f"ğŸ¯ è·³è½¬åˆ°æ¨¡å‹è®­ç»ƒ...")
        
        # è·³è½¬åˆ°æ¨¡å‹è®­ç»ƒéƒ¨åˆ†
        data_loaded_from_cache = True
        
    except Exception as e:
        print(f"âš ï¸  ç¼“å­˜åŠ è½½å¤±è´¥: {e}")
        print(f"ğŸ”„ å°†é‡æ–°åŠ è½½åŸå§‹æ•°æ®...")
        data_loaded_from_cache = False
else:
    data_loaded_from_cache = False

if not data_loaded_from_cache:
    # 1. åŠ è½½è®­ç»ƒé›†æ•°æ®
    print("\n1ï¸âƒ£ åŠ è½½è®­ç»ƒé›†æ•°æ®...")
    train_normal = load_data_from_directory(os.path.join(train_path, "APP_0"), 0)  # æ­£å¸¸æµé‡
    train_pcdn = load_data_from_directory(os.path.join(train_path, "APP_1"), 1)    # PCDNæµé‡

    # 2. åŠ è½½éªŒè¯é›†æ•°æ®
    print("\n2ï¸âƒ£ åŠ è½½éªŒè¯é›†æ•°æ®...")
    val_normal = load_data_from_directory(os.path.join(val_path, "APP_0"), 0)
    val_pcdn = load_data_from_directory(os.path.join(val_path, "APP_1"), 1)

    # 3. åŠ è½½æµ‹è¯•é›†æ•°æ®
    print("\n3ï¸âƒ£ åŠ è½½æµ‹è¯•é›†æ•°æ®...")
    test_normal = load_data_from_directory(os.path.join(test_path, "APP_0"), 0)
    test_pcdn = load_data_from_directory(os.path.join(test_path, "APP_1"), 1)

    # 4. åˆå¹¶æ•°æ®é›†
    print("\n4ï¸âƒ£ åˆå¹¶æ•°æ®é›†...")

    train_data = safe_concat([train_normal, train_pcdn], "è®­ç»ƒé›†")
    val_data = safe_concat([val_normal, val_pcdn], "éªŒè¯é›†")
    test_data = safe_concat([test_normal, test_pcdn], "æµ‹è¯•é›†")

    # æ£€æŸ¥æ•°æ®é›†æ˜¯å¦ä¸ºç©º
    if train_data.empty or val_data.empty or test_data.empty:
        print("âŒ æ•°æ®é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„å’Œæ–‡ä»¶")
        exit()

    print(f"è®­ç»ƒé›†: {len(train_data)} æ ·æœ¬ (æ­£å¸¸: {len(train_normal)}, PCDN: {len(train_pcdn)})")
    print(f"éªŒè¯é›†: {len(val_data)} æ ·æœ¬ (æ­£å¸¸: {len(val_normal)}, PCDN: {len(val_pcdn)})")
    print(f"æµ‹è¯•é›†: {len(test_data)} æ ·æœ¬ (æ­£å¸¸: {len(test_normal)}, PCDN: {len(test_pcdn)})")

    # 5. ç‰¹å¾æå–å’Œé¢„å¤„ç†
    print(f"\n5ï¸âƒ£ ç‰¹å¾æå–å’Œé¢„å¤„ç†...")
    print(f"é€‰æ‹©çš„ç‰¹å¾: {selected_features}")

    # é¢„å¤„ç†å„æ•°æ®é›†çš„ç‰¹å¾
    X_train = preprocess_features(train_data, selected_features)
    X_val = preprocess_features(val_data, selected_features)
    X_test = preprocess_features(test_data, selected_features)

    if X_train is None or X_val is None or X_test is None:
        print("âŒ ç‰¹å¾é¢„å¤„ç†å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç‰¹å¾åç§°")
        exit()

    # æå–æ ‡ç­¾
    y_train = train_data['label'].values
    y_val = val_data['label'].values  
    y_test = test_data['label'].values

    # 6. ç‰¹å¾æ ‡å‡†åŒ–ï¼ˆå¯¹äºå†³ç­–æ ‘å¯é€‰ï¼Œä½†ä¸ºäº†ä¸€è‡´æ€§ä¿ç•™ï¼‰
    print(f"\n6ï¸âƒ£ ç‰¹å¾æ ‡å‡†åŒ–...")
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)  # åªåœ¨è®­ç»ƒé›†ä¸Šfit
    X_val_scaled = scaler.transform(X_val)          # éªŒè¯é›†ä½¿ç”¨è®­ç»ƒé›†çš„å‚æ•°
    X_test_scaled = scaler.transform(X_test)        # æµ‹è¯•é›†ä½¿ç”¨è®­ç»ƒé›†çš„å‚æ•°

    print(f"âœ… æ ‡å‡†åŒ–å®Œæˆ")
    print(f"è®­ç»ƒé›†ç‰¹å¾å½¢çŠ¶: {X_train_scaled.shape}")
    print(f"éªŒè¯é›†ç‰¹å¾å½¢çŠ¶: {X_val_scaled.shape}")
    print(f"æµ‹è¯•é›†ç‰¹å¾å½¢çŠ¶: {X_test_scaled.shape}")
    
    # 7. ä¿å­˜é¢„å¤„ç†åçš„æ•°æ®åˆ°ç¼“å­˜
    print(f"\nğŸ’¾ ä¿å­˜é¢„å¤„ç†åçš„æ•°æ®åˆ°ç¼“å­˜...")
    try:
        # åˆ›å»ºç¼“å­˜ç›®å½•
        if not os.path.exists(cache_dir):
            os.makedirs(cache_dir)
            
        # å‡†å¤‡è¦ä¿å­˜çš„æ•°æ®
        cache_data = {
            'X_train_scaled': X_train_scaled,
            'X_val_scaled': X_val_scaled,
            'X_test_scaled': X_test_scaled,
            'y_train': y_train,
            'y_val': y_val,
            'y_test': y_test,
            'scaler': scaler,
            'selected_features': selected_features,
            'data_shapes': {
                'train': X_train_scaled.shape,
                'val': X_val_scaled.shape,
                'test': X_test_scaled.shape
            }
        }
        
        # ä¿å­˜åˆ°pickleæ–‡ä»¶
        with open(cache_file, 'wb') as f:
            pickle.dump(cache_data, f)
            
        print(f"âœ… æ•°æ®ç¼“å­˜ä¿å­˜æˆåŠŸ: {cache_file}")
        print(f"ğŸ“ ç¼“å­˜å¤§å°: {os.path.getsize(cache_file) / 1024 / 1024:.2f} MB")
        
    except Exception as e:
        print(f"âš ï¸  æ•°æ®ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
        print(f"ğŸ”„ ç»§ç»­æ­£å¸¸æµç¨‹...")

# æ— è®ºæ˜¯ä»ç¼“å­˜åŠ è½½è¿˜æ˜¯é‡æ–°å¤„ç†ï¼Œéƒ½ç»§ç»­æ‰§è¡Œæ•°æ®ç»Ÿè®¡
print(f"\n8ï¸âƒ£ æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯...")
print(f"è®­ç»ƒé›†ç‰¹å¾å½¢çŠ¶: {X_train_scaled.shape}")
print(f"éªŒè¯é›†ç‰¹å¾å½¢çŠ¶: {X_val_scaled.shape}")
print(f"æµ‹è¯•é›†ç‰¹å¾å½¢çŠ¶: {X_test_scaled.shape}")
print(f"è®­ç»ƒé›†æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(y_train)}")
print(f"éªŒè¯é›†æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(y_val)}")
print(f"æµ‹è¯•é›†æ ‡ç­¾åˆ†å¸ƒ: {np.bincount(y_test)}")

# æ˜¾ç¤ºç‰¹å¾ç»Ÿè®¡ï¼ˆä»åŸå§‹æ•°æ®é‡æ–°åˆ›å»ºï¼‰
if not data_loaded_from_cache:
    print(f"\nğŸ“Š ç‰¹å¾ç»Ÿè®¡ (è®­ç»ƒé›†):")
    feature_stats = pd.DataFrame(X_train, columns=selected_features).describe()
    print(feature_stats)
else:
    print(f"\nğŸ“Š ä½¿ç”¨ç‰¹å¾: {selected_features}")
    print(f"ğŸš€ æ•°æ®å·²ä»ç¼“å­˜åŠ è½½ï¼Œè·³è¿‡è¯¦ç»†ç»Ÿè®¡")

print(f"\nğŸ¯ æ•°æ®å‡†å¤‡å®Œæˆï¼Œå¼€å§‹å†³ç­–æ ‘æ¨¡å‹è®­ç»ƒ...")

# 9. å†³ç­–æ ‘æ¨¡å‹è®­ç»ƒï¼ˆå¸¦è¶…å‚æ•°ä¼˜åŒ–ï¼‰
print(f"\n9ï¸âƒ£ å¼€å§‹å†³ç­–æ ‘æ¨¡å‹è®­ç»ƒ...")
print("=" * 80)

# åˆ›å»ºè¾“å‡ºç›®å½•
output_dir = "output"
if not os.path.exists(output_dir):
    os.makedirs(output_dir)
    print(f"âœ… åˆ›å»ºè¾“å‡ºç›®å½•: {output_dir}")

# å®šä¹‰è¶…å‚æ•°ç½‘æ ¼
param_grid = {
    'max_depth': [4],
    'min_samples_split': [2, 5, 10, 15, 20, 30, 32, 35],
    'min_samples_leaf': [1, 2, 5, 8, 10, 12, 15, 16, 18],
    'criterion': ['gini', 'entropy']
}

print("ğŸ” å¼€å§‹è¶…å‚æ•°ç½‘æ ¼æœç´¢...")
print(f"ğŸ”§ æœç´¢ç©ºé—´: {len(param_grid['max_depth']) * len(param_grid['min_samples_split']) * len(param_grid['min_samples_leaf']) * len(param_grid['criterion'])} ç»„åˆ")

# åˆ›å»ºå†³ç­–æ ‘åˆ†ç±»å™¨
dt_base = DecisionTreeClassifier(random_state=42)

# ä½¿ç”¨ç½‘æ ¼æœç´¢æ‰¾åˆ°æœ€ä½³å‚æ•°
grid_search = GridSearchCV(
    dt_base, 
    param_grid, 
    cv=3,  # 3æŠ˜äº¤å‰éªŒè¯
    scoring='accuracy',
    n_jobs=-1,
    verbose=0
)

# åœ¨è®­ç»ƒé›†ä¸Šè¿›è¡Œç½‘æ ¼æœç´¢
grid_search.fit(X_train_scaled, y_train)

# è·å–æœ€ä½³æ¨¡å‹
dt_model = grid_search.best_estimator_

print(f"âœ… ç½‘æ ¼æœç´¢å®Œæˆ!")
print(f"ğŸ† æœ€ä½³å‚æ•°:")
for param, value in grid_search.best_params_.items():
    print(f"  {param}: {value}")
print(f"ğŸ“Š æœ€ä½³äº¤å‰éªŒè¯å¾—åˆ†: {grid_search.best_score_:.4f}")

print("=" * 80)

# 10. æ¨¡å‹é¢„æµ‹
print(f"\nğŸ”Ÿ æ¨¡å‹é¢„æµ‹...")

# åœ¨å„æ•°æ®é›†ä¸Šè¿›è¡Œé¢„æµ‹
y_train_pred = dt_model.predict(X_train_scaled)
y_train_prob = dt_model.predict_proba(X_train_scaled)[:, 1]

y_val_pred = dt_model.predict(X_val_scaled)
y_val_prob = dt_model.predict_proba(X_val_scaled)[:, 1]

y_test_pred = dt_model.predict(X_test_scaled)
y_test_prob = dt_model.predict_proba(X_test_scaled)[:, 1]

# 11. æ¨¡å‹è¯„ä¼°
print(f"\n1ï¸âƒ£1ï¸âƒ£ æ¨¡å‹è¯„ä¼°ç»“æœ...")

# å‡†ç¡®ç‡
train_acc = accuracy_score(y_train, y_train_pred)
val_acc = accuracy_score(y_val, y_val_pred)
test_acc = accuracy_score(y_test, y_test_pred)

# AUC (å®‰å…¨è®¡ç®—ï¼Œå¤„ç†å•ç±»åˆ«æƒ…å†µ)
def safe_auc_score(y_true, y_prob, set_name):
    """å®‰å…¨è®¡ç®—AUCï¼Œå¤„ç†å•ç±»åˆ«æƒ…å†µ"""
    if len(np.unique(y_true)) < 2:
        print(f"âš ï¸  {set_name} åªæœ‰ä¸€ä¸ªç±»åˆ«ï¼Œæ— æ³•è®¡ç®—AUC")
        return 0.5  # è¿”å›é»˜è®¤å€¼
    return roc_auc_score(y_true, y_prob)

train_auc = safe_auc_score(y_train, y_train_prob, "è®­ç»ƒé›†")
val_auc = safe_auc_score(y_val, y_val_prob, "éªŒè¯é›†")
test_auc = safe_auc_score(y_test, y_test_prob, "æµ‹è¯•é›†")

print(f"ğŸ“Š å‡†ç¡®ç‡ (Accuracy):")
print(f"  è®­ç»ƒé›†: {train_acc:.4f}")
print(f"  éªŒè¯é›†: {val_acc:.4f}")
print(f"  æµ‹è¯•é›†: {test_acc:.4f}")

print(f"\nğŸ“Š AUCå€¼:")
print(f"  è®­ç»ƒé›†: {train_auc:.4f}")
print(f"  éªŒè¯é›†: {val_auc:.4f}")
print(f"  æµ‹è¯•é›†: {test_auc:.4f}")

# è¯¦ç»†åˆ†ç±»æŠ¥å‘Š
print(f"\nğŸ“‹ æµ‹è¯•é›†è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
print(classification_report(y_test, y_test_pred, target_names=['Normal Traffic', 'PCDN Traffic']))

# 12. ç‰¹å¾é‡è¦æ€§åˆ†æ
print(f"\n1ï¸âƒ£2ï¸âƒ£ ç‰¹å¾é‡è¦æ€§åˆ†æ...")

# è·å–ç‰¹å¾é‡è¦æ€§
feature_importance = dt_model.feature_importances_
feature_names = selected_features

# åˆ›å»ºç‰¹å¾é‡è¦æ€§DataFrame
importance_df = pd.DataFrame({
    'feature': feature_names,
    'importance': feature_importance
}).sort_values('importance', ascending=False)

print(f"ğŸ“Š ç‰¹å¾é‡è¦æ€§æ’åº:")
for idx, row in importance_df.iterrows():
    print(f"  {row['feature']}: {row['importance']:.4f}")

# 13. å†³ç­–æ ‘ç»“æ„åˆ†æ
print(f"\n1ï¸âƒ£3ï¸âƒ£ å†³ç­–æ ‘ç»“æ„åˆ†æ...")

print(f"ğŸŒ³ å†³ç­–æ ‘ä¿¡æ¯:")
print(f"  æ ‘çš„æ·±åº¦: {dt_model.get_depth()}")
print(f"  å¶å­èŠ‚ç‚¹æ•°: {dt_model.get_n_leaves()}")
print(f"  æ€»èŠ‚ç‚¹æ•°: {dt_model.tree_.node_count}")

# æ‰“å°å†³ç­–æ ‘è§„åˆ™ï¼ˆç®€åŒ–ç‰ˆï¼‰
print(f"\nğŸ“‹ å†³ç­–æ ‘è§„åˆ™ (å‰10æ¡):")
tree_rules = export_text(dt_model, feature_names=selected_features, max_depth=3)
print(tree_rules)

print(f"\nğŸ¯ å¼€å§‹ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")

# 14. å¯è§†åŒ–ç»“æœ
print(f"\n1ï¸âƒ£4ï¸âƒ£ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")

# é¦–å…ˆåˆ›å»ºå†³ç­–æ ‘çš„å•ç‹¬å¯è§†åŒ–å›¾
print("ğŸŒ³ ç”Ÿæˆå†³ç­–æ ‘å•ç‹¬å¯è§†åŒ–å›¾...")

# ç¡®å®šåˆé€‚çš„æ˜¾ç¤ºæ·±åº¦ï¼ˆå¹³è¡¡æ¸…æ™°åº¦å’Œä¿¡æ¯é‡ï¼‰
tree_depth = dt_model.get_depth()
display_depth = min(tree_depth, 4)  # æœ€å¤šæ˜¾ç¤º4å±‚ä»¥ä¿æŒæ¸…æ™°

fig_tree_single, ax_tree_single = plt.subplots(1, 1, figsize=(24, 16))

# ä½¿ç”¨æ›´å¥½çš„é…è‰²å’Œæ ·å¼
plot_tree(dt_model, 
          feature_names=selected_features,
          class_names=['Normal Traffic', 'PCDN Traffic'],
          filled=True,
          rounded=True,
          max_depth=display_depth,
          fontsize=14,
          proportion=True,  # æ˜¾ç¤ºæ¯”ä¾‹ä¿¡æ¯
          impurity=True,    # æ˜¾ç¤ºä¸çº¯åº¦
          ax=ax_tree_single)

# è®¾ç½®æ ‡é¢˜å’Œæ ·å¼
title_text = f'Decision Tree for PCDN Traffic Classification\n'
title_text += f'(Showing top {display_depth} levels, Total depth: {tree_depth}, Total nodes: {dt_model.tree_.node_count})'
ax_tree_single.set_title(title_text, fontweight='bold', fontsize=18, pad=20)

# ç§»é™¤åæ ‡è½´
ax_tree_single.set_xticks([])
ax_tree_single.set_yticks([])
ax_tree_single.spines['top'].set_visible(False)
ax_tree_single.spines['right'].set_visible(False)
ax_tree_single.spines['bottom'].set_visible(False)
ax_tree_single.spines['left'].set_visible(False)

# æ·»åŠ å›¾ä¾‹è¯´æ˜
legend_text = """
ğŸ“‹ How to Read This Decision Tree:

ğŸ”¹ Node Information:
   â€¢ Feature condition: [feature â‰¤ threshold]
   â€¢ gini: Impurity measure (0.0 = pure, 0.5 = mixed)
   â€¢ samples: Number of training samples reaching this node
   â€¢ value: [Normal Traffic count, PCDN Traffic count]
   â€¢ class: Final prediction for this node

ğŸ”¹ Colors:
   â€¢ Orange tones: Predominantly Normal Traffic
   â€¢ Blue tones: Predominantly PCDN Traffic
   â€¢ Darker = more confident, Lighter = more mixed

ğŸ”¹ Decision Path:
   â€¢ Follow Yes (True) â†’ Left branch
   â€¢ Follow No (False) â†’ Right branch
   â€¢ Leaf nodes show final classification
"""

ax_tree_single.text(0.02, 0.02, legend_text, transform=ax_tree_single.transAxes, 
                   fontsize=11, verticalalignment='bottom',
                   bbox=dict(boxstyle="round,pad=0.8", facecolor="lightyellow", alpha=0.9, edgecolor="gray"))

plt.tight_layout()

# ä¿å­˜é«˜æ¸…çš„å†³ç­–æ ‘å›¾
try:
    plt.savefig(os.path.join(output_dir, 'decision_tree_single_clear.png'), 
                dpi=300, bbox_inches='tight', facecolor='white')
    print("ğŸ“Š æ¸…æ™°å†³ç­–æ ‘å›¾å·²ä¿å­˜ä¸º: output/decision_tree_single_clear.png")
except Exception as e:
    print(f"âš ï¸  å†³ç­–æ ‘å›¾ä¿å­˜å¤±è´¥: {e}")

plt.show()

# åˆ›å»ºå…¶ä»–åˆ†æå›¾è¡¨ (2x2å¸ƒå±€ï¼Œä¸åŒ…å«å†³ç­–æ ‘)
fig = plt.figure(figsize=(16, 12))
fig.suptitle('Decision Tree PCDN Traffic Classification - Performance Analysis', fontsize=16, fontweight='bold')

# 1. ç‰¹å¾é‡è¦æ€§å›¾
ax1 = plt.subplot(2, 2, 1)
colors = plt.cm.Set3(np.linspace(0, 1, len(importance_df)))
bars = ax1.bar(importance_df['feature'], importance_df['importance'], 
               color=colors)
ax1.set_title('Feature Importance Analysis', fontweight='bold')
ax1.set_xlabel('Feature Names')
ax1.set_ylabel('Importance Score')
ax1.tick_params(axis='x', rotation=45)

# åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
for bar, importance in zip(bars, importance_df['importance']):
    height = bar.get_height()
    ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,
             f'{importance:.3f}', ha='center', va='bottom', fontweight='bold')

# 2. ROCæ›²çº¿
ax2 = plt.subplot(2, 2, 2)

# å®‰å…¨ç»˜åˆ¶ROCæ›²çº¿
def safe_plot_roc(y_true, y_prob, label, ax):
    """å®‰å…¨ç»˜åˆ¶ROCæ›²çº¿"""
    if len(np.unique(y_true)) < 2:
        return  # è·³è¿‡å•ç±»åˆ«æƒ…å†µ
    fpr, tpr, _ = roc_curve(y_true, y_prob)
    ax.plot(fpr, tpr, label=label, linewidth=2)

safe_plot_roc(y_train, y_train_prob, f'Training Set (AUC = {train_auc:.3f})', ax2)
safe_plot_roc(y_val, y_val_prob, f'Validation Set (AUC = {val_auc:.3f})', ax2)
safe_plot_roc(y_test, y_test_prob, f'Test Set (AUC = {test_auc:.3f})', ax2)

ax2.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Random Classifier')
ax2.set_title('ROC Curve Comparison', fontweight='bold')
ax2.set_xlabel('False Positive Rate (FPR)')
ax2.set_ylabel('True Positive Rate (TPR)')
ax2.legend()
ax2.grid(True, alpha=0.3)

# 3. æ··æ·†çŸ©é˜µ
ax3 = plt.subplot(2, 2, 3)
cm = confusion_matrix(y_test, y_test_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax3,
            xticklabels=['Normal Traffic', 'PCDN Traffic'],
            yticklabels=['Normal Traffic', 'PCDN Traffic'])
ax3.set_title('Test Set Confusion Matrix', fontweight='bold')
ax3.set_xlabel('Predicted Label')
ax3.set_ylabel('True Label')

# 4. å‡†ç¡®ç‡å¯¹æ¯”
ax4 = plt.subplot(2, 2, 4)
datasets = ['Training Set', 'Validation Set', 'Test Set']
accuracies = [train_acc, val_acc, test_acc]
colors_acc = ['#FF9999', '#66B2FF', '#99FF99']

bars = ax4.bar(datasets, accuracies, color=colors_acc, alpha=0.8)
ax4.set_title('Accuracy Comparison Across Datasets', fontweight='bold')
ax4.set_ylabel('Accuracy')
ax4.set_ylim(0, 1.1)

# åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
for bar, acc in zip(bars, accuracies):
    height = bar.get_height()
    ax4.text(bar.get_x() + bar.get_width()/2., height + 0.02,
             f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')

plt.tight_layout()

# å®‰å…¨ä¿å­˜å›¾è¡¨
try:
    plt.savefig(os.path.join(output_dir, 'decision_tree_performance_analysis.png'), 
                dpi=300, bbox_inches='tight')
    print("ğŸ“Š æ€§èƒ½åˆ†æå›¾å·²ä¿å­˜ä¸º: output/decision_tree_performance_analysis.png")
except Exception as e:
    print(f"âš ï¸  æ€§èƒ½åˆ†æå›¾ä¿å­˜å¤±è´¥: {e}")
    print("ğŸ“Š å›¾è¡¨ä»åœ¨å†…å­˜ä¸­æ˜¾ç¤º")

plt.show()

# 14.5. é˜ˆå€¼ä¼˜åŒ–å¯è§†åŒ–
print(f"\n1ï¸âƒ£4ï¸âƒ£.5ï¸âƒ£ ç”Ÿæˆé˜ˆå€¼ä¼˜åŒ–å¯è§†åŒ–å›¾è¡¨...")

# é«˜çº§é˜ˆå€¼ä¼˜åŒ–åˆ†æå‡½æ•°
def advanced_threshold_optimization(y_true, y_prob, set_name="Test Set"):
    """
    é«˜çº§é˜ˆå€¼ä¼˜åŒ–å‡½æ•°ï¼Œä¸“é—¨ç”¨äºé™ä½æ­£å¸¸æµé‡è¯¯åˆ†ç±»
    åŒ…å«å¤šç§ä¼˜åŒ–ç­–ç•¥å’Œç²¾ç»†æœç´¢
    """
    print(f"\nğŸš€ {set_name} é«˜çº§é˜ˆå€¼ä¼˜åŒ–åˆ†æ:")
    print("=" * 60)
    
    # 1. ç²¾ç»†ç½‘æ ¼æœç´¢ï¼ˆ0.001æ­¥é•¿ï¼‰
    print("ğŸ” æ‰§è¡Œç²¾ç»†ç½‘æ ¼æœç´¢ï¼ˆæ­¥é•¿0.001ï¼‰...")
    fine_thresholds = np.arange(0.001, 1.000, 0.001)
    
    results = []
    for threshold in fine_thresholds:
        y_pred = (y_prob >= threshold).astype(int)
        
        # è®¡ç®—æ··æ·†çŸ©é˜µ
        tn = np.sum((y_true == 0) & (y_pred == 0))
        fp = np.sum((y_true == 0) & (y_pred == 1))
        fn = np.sum((y_true == 1) & (y_pred == 0))
        tp = np.sum((y_true == 1) & (y_pred == 1))
        
        # é¿å…é™¤é›¶é”™è¯¯
        precision = tp / (tp + fp + 1e-8)
        recall = tp / (tp + fn + 1e-8)
        f1 = 2 * precision * recall / (precision + recall + 1e-8)
        fpr = fp / (fp + tn + 1e-8)
        
        results.append({
            'threshold': threshold,
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'fpr': fpr,
            'fp': fp,
            'tp': tp,
            'tn': tn,
            'fn': fn,
            'total_normal': fp + tn,
            'total_pcdn': tp + fn
        })
    
    results_df = pd.DataFrame(results)
    
    # 2. å¤šç§ä¼˜åŒ–ç­–ç•¥
    strategies = {}
    
    # ç­–ç•¥1: æœ€å¤§F1åˆ†æ•°
    max_f1_row = results_df.loc[results_df['f1'].idxmax()]
    strategies['Max F1'] = max_f1_row.to_dict()
    
    # ç­–ç•¥2: æœ€å°è¯¯æŠ¥ç‡ï¼ˆåœ¨ä¿è¯ä¸€å®šå¬å›ç‡çš„å‰æä¸‹ï¼‰
    min_recall_threshold = 0.7  # è‡³å°‘70%å¬å›ç‡
    valid_recall_mask = results_df['recall'] >= min_recall_threshold
    if valid_recall_mask.any():
        min_fpr_row = results_df[valid_recall_mask].loc[results_df[valid_recall_mask]['fpr'].idxmin()]
        strategies['Min FPR (Recallâ‰¥70%)'] = min_fpr_row.to_dict()
    
    # ç­–ç•¥3: æä½è¯¯æŠ¥ç‡ï¼ˆFPR â‰¤ 1%ï¼‰
    ultra_low_fpr_mask = results_df['fpr'] <= 0.01
    if ultra_low_fpr_mask.any():
        ultra_low_fpr_candidates = results_df[ultra_low_fpr_mask]
        best_ultra_low = ultra_low_fpr_candidates.loc[ultra_low_fpr_candidates['f1'].idxmax()]
        strategies['Ultra Low FPR (â‰¤1%)'] = best_ultra_low.to_dict()
    
    # ç­–ç•¥4: æä¸¥æ ¼è¯¯æŠ¥ç‡ï¼ˆFPR â‰¤ 0.5%ï¼‰
    extreme_low_fpr_mask = results_df['fpr'] <= 0.005
    if extreme_low_fpr_mask.any():
        extreme_low_fpr_candidates = results_df[extreme_low_fpr_mask]
        best_extreme_low = extreme_low_fpr_candidates.loc[extreme_low_fpr_candidates['f1'].idxmax()]
        strategies['Extreme Low FPR (â‰¤0.5%)'] = best_extreme_low.to_dict()
    
    # ç­–ç•¥5: å›ºå®šè¯¯æŠ¥æ ·æœ¬æ•°ï¼ˆæœ€å¤šå…è®¸Nä¸ªæ­£å¸¸æµé‡è¯¯åˆ†ç±»ï¼‰
    total_normal = results_df['total_normal'].iloc[0]
    max_fp_samples = [5, 10, 20, 30, 50]  # æœ€å¤šå…è®¸è¯¯åˆ†ç±»çš„æ­£å¸¸æµé‡æ ·æœ¬æ•°
    
    for max_fp in max_fp_samples:
        if max_fp < total_normal:
            valid_fp_mask = results_df['fp'] <= max_fp
            if valid_fp_mask.any():
                fp_candidates = results_df[valid_fp_mask]
                best_fp = fp_candidates.loc[fp_candidates['f1'].idxmax()]
                strategies[f'Max {max_fp} FP Samples'] = best_fp.to_dict()
    
    # ç­–ç•¥6: é«˜ç²¾ç¡®ç‡å¤šå±‚çº§
    precision_levels = [0.95, 0.96, 0.97, 0.98, 0.99]
    for prec_level in precision_levels:
        high_prec_mask = results_df['precision'] >= prec_level
        if high_prec_mask.any():
            high_prec_candidates = results_df[high_prec_mask]
            best_high_prec = high_prec_candidates.loc[high_prec_candidates['f1'].idxmax()]
            strategies[f'Precision â‰¥{prec_level*100:.0f}%'] = best_high_prec.to_dict()
    
    # ç­–ç•¥7: ä¸šåŠ¡ä»£ä»·æœ€å°åŒ–ï¼ˆå‡è®¾è¯¯æŠ¥ä»£ä»·æ˜¯æ¼æŠ¥ä»£ä»·çš„Nå€ï¼‰
    cost_ratios = [2, 5, 10, 20]  # è¯¯æŠ¥ä»£ä»· / æ¼æŠ¥ä»£ä»·
    for cost_ratio in cost_ratios:
        # æ€»ä»£ä»· = FP * cost_ratio + FN * 1
        results_df[f'total_cost_{cost_ratio}'] = results_df['fp'] * cost_ratio + results_df['fn']
        min_cost_row = results_df.loc[results_df[f'total_cost_{cost_ratio}'].idxmin()]
        strategies[f'Min Cost (FP:{cost_ratio}Ã—FN)'] = min_cost_row.to_dict()
    
    print(f"âœ… ç²¾ç»†æœç´¢å®Œæˆï¼Œå…±æµ‹è¯• {len(fine_thresholds)} ä¸ªé˜ˆå€¼")
    print(f"ğŸ“Š æ‰¾åˆ° {len(strategies)} ç§ä¼˜åŒ–ç­–ç•¥")
    
    return strategies, results_df

def threshold_analysis(y_true, y_prob, set_name="Test Set"):
    """
    ä¿æŒåŸæœ‰çš„é˜ˆå€¼åˆ†æå‡½æ•°ä»¥å…¼å®¹ç°æœ‰ä»£ç 
    """
    strategies, _ = advanced_threshold_optimization(y_true, y_prob, set_name)
    
    # ä¸ºäº†å…¼å®¹æ€§ï¼Œè¿”å›ä¸€äº›åŸºæœ¬çš„æ›²çº¿æ•°æ®
    precision, recall, thresholds = precision_recall_curve(y_true, y_prob)
    f1_scores = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-8)
    
    return strategies, precision, recall, thresholds, f1_scores

# åˆ›å»ºé˜ˆå€¼åˆ†æå›¾è¡¨
fig_threshold = plt.figure(figsize=(20, 12))
fig_threshold.suptitle('Threshold Optimization Analysis - Reducing False Positive Rate', fontsize=16, fontweight='bold')

# è®¡ç®—ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿æ•°æ®
test_precision_full, test_recall_full, test_thresholds_full = precision_recall_curve(y_test, y_test_prob)
test_f1_scores_full = 2 * (test_precision_full[:-1] * test_recall_full[:-1]) / (test_precision_full[:-1] + test_recall_full[:-1] + 1e-8)

# è®¡ç®—è¯¯æŠ¥ç‡æ›²çº¿
test_fpr_list = []
for threshold in test_thresholds_full:
    y_pred_thresh = (y_test_prob >= threshold).astype(int)
    tn = np.sum((y_test == 0) & (y_pred_thresh == 0))
    fp = np.sum((y_test == 0) & (y_pred_thresh == 1))
    fpr = fp / (fp + tn + 1e-8)
    test_fpr_list.append(fpr)

test_fpr_array = np.array(test_fpr_list)

# 1. ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿
ax1 = plt.subplot(2, 3, 1)
ax1.plot(test_recall_full, test_precision_full, 'b-', linewidth=2, label='PR Curve')
ax1.axhline(y=0.9, color='orange', linestyle='--', alpha=0.7, label='90% Precision')
ax1.axhline(y=0.95, color='red', linestyle='--', alpha=0.7, label='95% Precision')
ax1.set_xlabel('Recall (Sensitivity)')
ax1.set_ylabel('Precision')
ax1.set_title('Precision-Recall Curve', fontweight='bold')
ax1.grid(True, alpha=0.3)
ax1.legend()

# 2. F1åˆ†æ•°vsé˜ˆå€¼
ax2 = plt.subplot(2, 3, 2)
ax2.plot(test_thresholds_full, test_f1_scores_full, 'g-', linewidth=2, label='F1 Score')
max_f1_idx = np.argmax(test_f1_scores_full)
ax2.scatter(test_thresholds_full[max_f1_idx], test_f1_scores_full[max_f1_idx], 
           color='red', s=100, zorder=5, label=f'Max F1 (t={test_thresholds_full[max_f1_idx]:.3f})')
ax2.axvline(x=0.5, color='blue', linestyle='--', alpha=0.7, label='Default (0.5)')
ax2.set_xlabel('Threshold')
ax2.set_ylabel('F1 Score')
ax2.set_title('F1 Score vs Threshold', fontweight='bold')
ax2.grid(True, alpha=0.3)
ax2.legend()

# 3. è¯¯æŠ¥ç‡vsé˜ˆå€¼
ax3 = plt.subplot(2, 3, 3)
ax3.plot(test_thresholds_full, test_fpr_array, 'r-', linewidth=2, label='False Positive Rate')
ax3.axhline(y=0.05, color='orange', linestyle='--', alpha=0.7, label='5% FPR Target')
ax3.axvline(x=0.5, color='blue', linestyle='--', alpha=0.7, label='Default (0.5)')
ax3.set_xlabel('Threshold')
ax3.set_ylabel('False Positive Rate')
ax3.set_title('False Positive Rate vs Threshold', fontweight='bold')
ax3.grid(True, alpha=0.3)
ax3.legend()

# 4. ç²¾ç¡®ç‡vsé˜ˆå€¼
ax4 = plt.subplot(2, 3, 4)
ax4.plot(test_thresholds_full, test_precision_full[:-1], 'purple', linewidth=2, label='Precision')
ax4.axhline(y=0.9, color='orange', linestyle='--', alpha=0.7, label='90% Target')
ax4.axhline(y=0.95, color='red', linestyle='--', alpha=0.7, label='95% Target')
ax4.axvline(x=0.5, color='blue', linestyle='--', alpha=0.7, label='Default (0.5)')
ax4.set_xlabel('Threshold')
ax4.set_ylabel('Precision')
ax4.set_title('Precision vs Threshold', fontweight='bold')
ax4.grid(True, alpha=0.3)
ax4.legend()

# 5. å¬å›ç‡vsé˜ˆå€¼
ax5 = plt.subplot(2, 3, 5)
ax5.plot(test_thresholds_full, test_recall_full[:-1], 'brown', linewidth=2, label='Recall')
ax5.axvline(x=0.5, color='blue', linestyle='--', alpha=0.7, label='Default (0.5)')
ax5.set_xlabel('Threshold')
ax5.set_ylabel('Recall (Sensitivity)')
ax5.set_title('Recall vs Threshold', fontweight='bold')
ax5.grid(True, alpha=0.3)
ax5.legend()

# 6. é˜ˆå€¼ç­–ç•¥å¯¹æ¯”
ax6 = plt.subplot(2, 3, 6)

# é¢„å…ˆè®¡ç®—ç­–ç•¥æ•°æ®ï¼Œé¿å…å˜é‡æœªå®šä¹‰é—®é¢˜
temp_strategies, _, _, _, _ = threshold_analysis(y_test, y_test_prob, "æµ‹è¯•é›†ï¼ˆé¢„è®¡ç®—ï¼‰")

if temp_strategies:
    strategy_names = list(temp_strategies.keys())
    precision_values = [temp_strategies[name]['precision'] for name in strategy_names]
    recall_values = [temp_strategies[name]['recall'] for name in strategy_names]
    f1_values = [temp_strategies[name]['f1'] for name in strategy_names]
    
    x_pos = np.arange(len(strategy_names))
    width = 0.25
    
    bars1 = ax6.bar(x_pos - width, precision_values, width, label='Precision', alpha=0.8)
    bars2 = ax6.bar(x_pos, recall_values, width, label='Recall', alpha=0.8) 
    bars3 = ax6.bar(x_pos + width, f1_values, width, label='F1 Score', alpha=0.8)
    
    ax6.set_xlabel('Strategy')
    ax6.set_ylabel('Score')
    ax6.set_title('Strategy Comparison', fontweight='bold')
    ax6.set_xticks(x_pos)
    ax6.set_xticklabels([name.replace(' ', '\n') for name in strategy_names], fontsize=9)
    ax6.legend()
    ax6.grid(True, alpha=0.3)

plt.tight_layout()

# ä¿å­˜é˜ˆå€¼åˆ†æå›¾
try:
    plt.savefig(os.path.join(output_dir, 'threshold_optimization_analysis.png'), 
                dpi=300, bbox_inches='tight')
    print("ğŸ“Š é˜ˆå€¼ä¼˜åŒ–åˆ†æå›¾å·²ä¿å­˜ä¸º: output/threshold_optimization_analysis.png")
except Exception as e:
    print(f"âš ï¸  é˜ˆå€¼åˆ†æå›¾ä¿å­˜å¤±è´¥: {e}")

plt.show()

# 15. é˜ˆå€¼ä¼˜åŒ–åˆ†æ - é™ä½è¯¯æŠ¥ç‡
print(f"\n1ï¸âƒ£5ï¸âƒ£ é˜ˆå€¼ä¼˜åŒ–åˆ†æ - é™ä½æ­£å¸¸æµé‡è¯¯åˆ†ç±»...")
print("=" * 80)

# å¯¹æµ‹è¯•é›†è¿›è¡Œé«˜çº§é˜ˆå€¼åˆ†æ
print("ğŸ¯ é‡ç‚¹åˆ†æ: å¦‚ä½•æœ€å¤§é™åº¦é™ä½æ­£å¸¸æµé‡è¢«è¯¯åˆ†ç±»ä¸ºPCDNæµé‡çš„æƒ…å†µ")

# æ‰§è¡Œé«˜çº§é˜ˆå€¼ä¼˜åŒ–
test_strategies, results_df = advanced_threshold_optimization(y_test, y_test_prob, "æµ‹è¯•é›†")

# è¯¦ç»†å±•ç¤ºæ‰€æœ‰ä¼˜åŒ–ç­–ç•¥
print(f"\nğŸ“Š é«˜çº§é˜ˆå€¼ä¼˜åŒ–ç­–ç•¥è¯¦ç»†å¯¹æ¯”:")
print(f"{'ç­–ç•¥':<30} {'é˜ˆå€¼':<8} {'ç²¾ç¡®ç‡':<8} {'å¬å›ç‡':<8} {'F1åˆ†æ•°':<8} {'è¯¯æŠ¥ç‡':<8} {'è¯¯æŠ¥æ ·æœ¬æ•°':<10}")
print("=" * 110)

# æŒ‰è¯¯æŠ¥ç‡æ’åºæ˜¾ç¤º
strategies_by_fpr = sorted(test_strategies.items(), key=lambda x: x[1].get('fpr', 1.0))

for strategy_name, metrics in strategies_by_fpr:
    fpr = metrics.get('fpr', 0)
    fp_samples = int(metrics.get('fp', 0))
    print(f"{strategy_name:<30} {metrics['threshold']:<8.3f} {metrics['precision']:<8.3f} "
          f"{metrics['recall']:<8.3f} {metrics['f1']:<8.3f} {fpr:<8.4f} {fp_samples:<10}")

# æ‰¾å‡ºæœ€ä¼˜çš„å‡ ä¸ªç­–ç•¥è¿›è¡Œé‡ç‚¹åˆ†æ
print(f"\nğŸ† é‡ç‚¹æ¨èç­–ç•¥:")
print("=" * 60)

# 1. æœ€ä¸¥æ ¼è¯¯æŠ¥æ§åˆ¶
extreme_strategies = [name for name in test_strategies.keys() if 'Extreme' in name or 'Ultra' in name or 'Max 5 FP' in name or 'Max 10 FP' in name]
if extreme_strategies:
    print(f"ğŸ”´ æä¸¥æ ¼è¯¯æŠ¥æ§åˆ¶ (é€‚åˆå¯¹è¯¯æŠ¥é›¶å®¹å¿çš„åœºæ™¯):")
    for strategy_name in extreme_strategies[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
        if strategy_name in test_strategies:
            metrics = test_strategies[strategy_name]
            fp_samples = int(metrics.get('fp', 0))
            total_normal = int(metrics.get('total_normal', 1))
            fpr_pct = metrics.get('fpr', 0) * 100
            print(f"  â€¢ {strategy_name}")
            print(f"    é˜ˆå€¼: {metrics['threshold']:.4f} | è¯¯æŠ¥ç‡: {fpr_pct:.2f}% | è¯¯æŠ¥æ ·æœ¬: {fp_samples}/{total_normal}")
            print(f"    ç²¾ç¡®ç‡: {metrics['precision']:.3f} | å¬å›ç‡: {metrics['recall']:.3f} | F1: {metrics['f1']:.3f}")
            print()

# 2. å¹³è¡¡ç­–ç•¥
balanced_strategies = [name for name in test_strategies.keys() if 'Cost' in name or 'Max F1' in name]
if balanced_strategies:
    print(f"ğŸŸ¡ å¹³è¡¡ç­–ç•¥ (é€‚åˆä¸€èˆ¬ä¸šåŠ¡åœºæ™¯):")
    for strategy_name in balanced_strategies[:3]:
        if strategy_name in test_strategies:
            metrics = test_strategies[strategy_name]
            fp_samples = int(metrics.get('fp', 0))
            total_normal = int(metrics.get('total_normal', 1))
            fpr_pct = metrics.get('fpr', 0) * 100
            print(f"  â€¢ {strategy_name}")
            print(f"    é˜ˆå€¼: {metrics['threshold']:.4f} | è¯¯æŠ¥ç‡: {fpr_pct:.2f}% | è¯¯æŠ¥æ ·æœ¬: {fp_samples}/{total_normal}")
            print(f"    ç²¾ç¡®ç‡: {metrics['precision']:.3f} | å¬å›ç‡: {metrics['recall']:.3f} | F1: {metrics['f1']:.3f}")
            print()

# ä¸ºäº†å…¼å®¹æ€§ï¼Œä¿æŒåŸæœ‰å˜é‡
_, test_precision, test_recall, test_thresholds, test_f1_scores = threshold_analysis(y_test, y_test_prob, "æµ‹è¯•é›†ï¼ˆå…¼å®¹æ€§ï¼‰")

# è¯¦ç»†åˆ†æé»˜è®¤é˜ˆå€¼vsæœ€ä¼˜é˜ˆå€¼
print(f"\nğŸ” é»˜è®¤é˜ˆå€¼(0.5) vs ä½è¯¯æŠ¥é˜ˆå€¼ è¯¦ç»†å¯¹æ¯”:")

# é»˜è®¤é˜ˆå€¼æ€§èƒ½
default_threshold = 0.5
y_test_pred_default = (y_test_prob >= default_threshold).astype(int)
default_precision = precision_score(y_test, y_test_pred_default)
default_recall = recall_score(y_test, y_test_pred_default)
default_f1 = f1_score(y_test, y_test_pred_default)

# è®¡ç®—é»˜è®¤é˜ˆå€¼çš„æ··æ·†çŸ©é˜µ
default_cm = confusion_matrix(y_test, y_test_pred_default)
default_tn, default_fp, default_fn, default_tp = default_cm.ravel()
default_fpr = default_fp / (default_fp + default_tn)

print(f"\nğŸ“ˆ é»˜è®¤é˜ˆå€¼ (0.5) æ€§èƒ½:")
print(f"  ç²¾ç¡®ç‡: {default_precision:.4f}")
print(f"  å¬å›ç‡: {default_recall:.4f}")
print(f"  F1åˆ†æ•°: {default_f1:.4f}")
print(f"  è¯¯æŠ¥ç‡: {default_fpr:.4f} ({default_fpr*100:.2f}%)")
print(f"  è¯¯åˆ†ç±»çš„æ­£å¸¸æµé‡: {default_fp} / {default_fp + default_tn} ({default_fpr*100:.1f}%)")

# å¦‚æœæœ‰ä½è¯¯æŠ¥ç‡ç­–ç•¥ï¼Œæ˜¾ç¤ºå¯¹æ¯”
if 'Low False Positive (FPR â‰¤5%)' in test_strategies:
    low_fpr_strategy = test_strategies['Low False Positive (FPR â‰¤5%)']
    optimal_threshold = low_fpr_strategy['threshold']
    
    y_test_pred_optimal = (y_test_prob >= optimal_threshold).astype(int)
    optimal_cm = confusion_matrix(y_test, y_test_pred_optimal)
    optimal_tn, optimal_fp, optimal_fn, optimal_tp = optimal_cm.ravel()
    optimal_fpr = optimal_fp / (optimal_fp + optimal_tn)
    
    print(f"\nğŸ¯ ä½è¯¯æŠ¥é˜ˆå€¼ ({optimal_threshold:.3f}) æ€§èƒ½:")
    print(f"  ç²¾ç¡®ç‡: {low_fpr_strategy['precision']:.4f}")
    print(f"  å¬å›ç‡: {low_fpr_strategy['recall']:.4f}")
    print(f"  F1åˆ†æ•°: {low_fpr_strategy['f1']:.4f}")
    print(f"  è¯¯æŠ¥ç‡: {optimal_fpr:.4f} ({optimal_fpr*100:.2f}%)")
    print(f"  è¯¯åˆ†ç±»çš„æ­£å¸¸æµé‡: {optimal_fp} / {optimal_fp + optimal_tn} ({optimal_fpr*100:.1f}%)")
    
    print(f"\nâœ… æ”¹è¿›æ•ˆæœ:")
    fp_reduction = default_fp - optimal_fp
    fpr_reduction = default_fpr - optimal_fpr
    print(f"  è¯¯åˆ†ç±»æ­£å¸¸æµé‡å‡å°‘: {fp_reduction} ä¸ªæ ·æœ¬")
    print(f"  è¯¯æŠ¥ç‡é™ä½: {fpr_reduction:.4f} ({fpr_reduction*100:.2f} ä¸ªç™¾åˆ†ç‚¹)")
    if default_fp > 0:
        print(f"  è¯¯æŠ¥ç‡ç›¸å¯¹é™ä½: {(fp_reduction/default_fp)*100:.1f}%")

# 16. ç”Ÿæˆå®Œæ•´çš„å†³ç­–æ ‘æ–‡æœ¬è§„åˆ™
print(f"\n1ï¸âƒ£6ï¸âƒ£ ç”Ÿæˆå®Œæ•´å†³ç­–æ ‘è§„åˆ™...")

# å¯¼å‡ºå®Œæ•´çš„å†³ç­–æ ‘è§„åˆ™åˆ°æ–‡ä»¶
try:
    full_tree_rules = export_text(dt_model, feature_names=selected_features)
    rules_file = os.path.join(output_dir, 'decision_tree_rules.txt')
    with open(rules_file, 'w', encoding='utf-8') as f:
        f.write("Decision Tree Rules for PCDN Traffic Classification\n")
        f.write("=" * 60 + "\n\n")
        f.write(f"Model Parameters:\n")
        for param, value in grid_search.best_params_.items():
            f.write(f"  {param}: {value}\n")
        f.write(f"\nTree Structure:\n")
        f.write(f"  Tree Depth: {dt_model.get_depth()}\n")
        f.write(f"  Number of Leaves: {dt_model.get_n_leaves()}\n")
        f.write(f"  Total Nodes: {dt_model.tree_.node_count}\n\n")
        
        # æ·»åŠ é˜ˆå€¼ä¼˜åŒ–ä¿¡æ¯
        if test_strategies:
            f.write("Threshold Optimization Results:\n")
            f.write("-" * 40 + "\n")
            f.write("Recommended thresholds to reduce false positive rate:\n\n")
            for strategy_name, metrics in test_strategies.items():
                f.write(f"{strategy_name}:\n")
                f.write(f"  Threshold: {metrics['threshold']:.4f}\n")
                f.write(f"  Precision: {metrics['precision']:.4f}\n")
                f.write(f"  Recall: {metrics['recall']:.4f}\n")
                f.write(f"  F1 Score: {metrics['f1']:.4f}\n")
                if 'fpr' in metrics:
                    f.write(f"  False Positive Rate: {metrics['fpr']:.4f}\n")
                f.write("\n")
            
            f.write("Usage Recommendations:\n")
            f.write("- For minimum false positives: Use High Precision strategy\n")
            f.write("- For balanced performance: Use Max F1 strategy\n")
            f.write("- For production deployment: Choose threshold based on business requirements\n\n")
        
        f.write("Decision Rules:\n")
        f.write("-" * 40 + "\n")
        f.write(full_tree_rules)
    
    print(f"ğŸ“ å®Œæ•´å†³ç­–æ ‘è§„åˆ™å·²ä¿å­˜ä¸º: output/decision_tree_rules.txt")
    
    # åŒæ—¶ä¿å­˜é˜ˆå€¼ä¼˜åŒ–ç»“æœåˆ°å•ç‹¬æ–‡ä»¶
    if test_strategies:
        threshold_report_file = os.path.join(output_dir, 'threshold_optimization_report.txt')
        with open(threshold_report_file, 'w', encoding='utf-8') as f:
            f.write("Threshold Optimization Report for PCDN Traffic Classification\n")
            f.write("=" * 70 + "\n\n")
            f.write("ç›®æ ‡: é™ä½æ­£å¸¸æµé‡è¯¯åˆ†ç±»ä¸ºPCDNæµé‡çš„è¯¯æŠ¥ç‡\n\n")
            
            f.write("åˆ†ææ–¹æ³•:\n")
            f.write("é€šè¿‡è°ƒæ•´åˆ†ç±»é˜ˆå€¼æ¥ä¼˜åŒ–ç²¾ç¡®ç‡ã€å¬å›ç‡å’ŒF1åˆ†æ•°ï¼Œç‰¹åˆ«å…³æ³¨é™ä½è¯¯æŠ¥ç‡\n\n")
            
            f.write("æ¨èé˜ˆå€¼ç­–ç•¥:\n")
            f.write("-" * 30 + "\n")
            
            for strategy_name, metrics in test_strategies.items():
                f.write(f"\n{strategy_name}:\n")
                f.write(f"  æ¨èé˜ˆå€¼: {metrics['threshold']:.4f}\n")
                f.write(f"  ç²¾ç¡®ç‡: {metrics['precision']:.4f} ({metrics['precision']*100:.1f}%)\n")
                f.write(f"  å¬å›ç‡: {metrics['recall']:.4f} ({metrics['recall']*100:.1f}%)\n")
                f.write(f"  F1åˆ†æ•°: {metrics['f1']:.4f}\n")
                if 'fpr' in metrics:
                    f.write(f"  è¯¯æŠ¥ç‡: {metrics['fpr']:.4f} ({metrics['fpr']*100:.1f}%)\n")
                
                # æ·»åŠ åº”ç”¨åœºæ™¯è¯´æ˜
                if 'High Precision' in strategy_name:
                    f.write(f"  é€‚ç”¨åœºæ™¯: å¯¹è¯¯æŠ¥æå…¶æ•æ„Ÿçš„ç”Ÿäº§ç¯å¢ƒ\n")
                elif 'Low False Positive' in strategy_name:
                    f.write(f"  é€‚ç”¨åœºæ™¯: éœ€è¦æ§åˆ¶è¯¯æŠ¥ç‡åœ¨5%ä»¥ä¸‹çš„ä¸šåŠ¡åœºæ™¯\n")
                elif 'Max F1' in strategy_name:
                    f.write(f"  é€‚ç”¨åœºæ™¯: éœ€è¦å¹³è¡¡ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„ä¸€èˆ¬åœºæ™¯\n")
                elif 'Balanced' in strategy_name:
                    f.write(f"  é€‚ç”¨åœºæ™¯: å¯¹ç²¾ç¡®ç‡æœ‰ä¸€å®šè¦æ±‚ä½†ä¸è¿‡åˆ†ä¸¥æ ¼çš„åœºæ™¯\n")
            
            f.write(f"\nå®æ–½å»ºè®®:\n")
            f.write("-" * 20 + "\n")
            f.write("1. æ ¹æ®ä¸šåŠ¡å¯¹è¯¯æŠ¥çš„å®¹å¿åº¦é€‰æ‹©åˆé€‚çš„ç­–ç•¥\n")
            f.write("2. åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å…ˆç”¨å°æµé‡æµ‹è¯•é€‰å®šé˜ˆå€¼çš„æ•ˆæœ\n") 
            f.write("3. å®šæœŸé‡æ–°è¯„ä¼°å’Œè°ƒæ•´é˜ˆå€¼ï¼Œé€‚åº”æ•°æ®åˆ†å¸ƒçš„å˜åŒ–\n")
            f.write("4. å»ºè®®åŒæ—¶ç›‘æ§ç²¾ç¡®ç‡ã€å¬å›ç‡å’ŒF1åˆ†æ•°çš„å˜åŒ–\n")
        
        print(f"ğŸ“ é˜ˆå€¼ä¼˜åŒ–æŠ¥å‘Šå·²ä¿å­˜ä¸º: output/threshold_optimization_report.txt")
        
        # ç”Ÿæˆé«˜çº§é˜ˆå€¼åˆ†æçš„è¯¦ç»†æŠ¥å‘Š
        advanced_report_file = os.path.join(output_dir, 'advanced_threshold_analysis.txt')
        with open(advanced_report_file, 'w', encoding='utf-8') as f:
            f.write("Advanced Threshold Analysis Report - False Positive Minimization\n")
            f.write("=" * 80 + "\n\n")
            
            f.write("ğŸ¯ åˆ†æç›®æ ‡: æœ€å¤§é™åº¦é™ä½æ­£å¸¸æµé‡è¯¯åˆ†ç±»ä¸ºPCDNæµé‡çš„è¯¯æŠ¥ç‡\n\n")
            
            f.write("ğŸ” åˆ†ææ–¹æ³•:\n")
            f.write("- ç²¾ç»†ç½‘æ ¼æœç´¢: ä½¿ç”¨0.001æ­¥é•¿æµ‹è¯•999ä¸ªé˜ˆå€¼ç‚¹\n")
            f.write("- å¤šç»´åº¦ä¼˜åŒ–: åŒæ—¶è€ƒè™‘ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°ã€è¯¯æŠ¥ç‡ã€è¯¯æŠ¥æ ·æœ¬æ•°\n")
            f.write("- ä¸šåŠ¡åœºæ™¯é€‚é…: æä¾›ä¸åŒä¸¥æ ¼ç¨‹åº¦çš„è¯¯æŠ¥æ§åˆ¶ç­–ç•¥\n")
            f.write("- ä»£ä»·æ•æ„Ÿåˆ†æ: è€ƒè™‘è¯¯æŠ¥å’Œæ¼æŠ¥çš„ä¸åŒä¸šåŠ¡ä»£ä»·\n\n")
            
            f.write("ğŸ“Š æµ‹è¯•æ•°æ®ç»Ÿè®¡:\n")
            if test_strategies:
                sample_metrics = list(test_strategies.values())[0]
                total_normal = int(sample_metrics.get('total_normal', 0))
                total_pcdn = int(sample_metrics.get('total_pcdn', 0))
                f.write(f"- æ­£å¸¸æµé‡æ ·æœ¬: {total_normal:,}\n")
                f.write(f"- PCDNæµé‡æ ·æœ¬: {total_pcdn:,}\n")
                f.write(f"- æ€»æµ‹è¯•æ ·æœ¬: {total_normal + total_pcdn:,}\n")
                f.write(f"- æ ·æœ¬æ¯”ä¾‹: æ­£å¸¸:{total_normal/(total_normal+total_pcdn)*100:.1f}% | PCDN:{total_pcdn/(total_normal+total_pcdn)*100:.1f}%\n\n")
            
            # æŒ‰è¯¯æŠ¥ç‡æ’åºå±•ç¤ºæ‰€æœ‰ç­–ç•¥
            f.write("ğŸ† ä¼˜åŒ–ç­–ç•¥è¯¦ç»†åˆ†æ (æŒ‰è¯¯æŠ¥ç‡ä»ä½åˆ°é«˜æ’åº):\n")
            f.write("-" * 80 + "\n")
            
            strategies_by_fpr = sorted(test_strategies.items(), key=lambda x: x[1].get('fpr', 1.0))
            
            for i, (strategy_name, metrics) in enumerate(strategies_by_fpr, 1):
                f.write(f"\n{i}. {strategy_name}:\n")
                f.write(f"   æ¨èé˜ˆå€¼: {metrics['threshold']:.6f}\n")
                f.write(f"   æ€§èƒ½æŒ‡æ ‡:\n")
                f.write(f"     - ç²¾ç¡®ç‡: {metrics['precision']:.4f} ({metrics['precision']*100:.2f}%)\n")
                f.write(f"     - å¬å›ç‡: {metrics['recall']:.4f} ({metrics['recall']*100:.2f}%)\n")
                f.write(f"     - F1åˆ†æ•°: {metrics['f1']:.4f}\n")
                f.write(f"     - è¯¯æŠ¥ç‡: {metrics.get('fpr', 0):.6f} ({metrics.get('fpr', 0)*100:.4f}%)\n")
                f.write(f"   è¯¯åˆ†ç±»ç»Ÿè®¡:\n")
                f.write(f"     - è¯¯æŠ¥æ ·æœ¬æ•° (FP): {int(metrics.get('fp', 0)):,}\n")
                f.write(f"     - æ¼æŠ¥æ ·æœ¬æ•° (FN): {int(metrics.get('fn', 0)):,}\n")
                f.write(f"     - æ­£ç¡®è¯†åˆ«æ­£å¸¸æµé‡: {int(metrics.get('tn', 0)):,}\n")
                f.write(f"     - æ­£ç¡®è¯†åˆ«PCDNæµé‡: {int(metrics.get('tp', 0)):,}\n")
                
                # ä¸šåŠ¡å½±å“åˆ†æ
                fp_rate_pct = metrics.get('fpr', 0) * 100
                if fp_rate_pct <= 0.5:
                    impact_level = "æä½å½±å“"
                    recommendation = "é€‚åˆå¯¹è¯¯æŠ¥æå…¶æ•æ„Ÿçš„å…³é”®ä¸šåŠ¡"
                elif fp_rate_pct <= 1.0:
                    impact_level = "å¾ˆä½å½±å“"
                    recommendation = "é€‚åˆå¯¹è¯¯æŠ¥æ•æ„Ÿçš„é‡è¦ä¸šåŠ¡"
                elif fp_rate_pct <= 2.0:
                    impact_level = "ä½å½±å“"
                    recommendation = "é€‚åˆä¸€èˆ¬ä¸šåŠ¡åœºæ™¯"
                elif fp_rate_pct <= 5.0:
                    impact_level = "ä¸­ç­‰å½±å“"
                    recommendation = "é€‚åˆå¯¹å¬å›ç‡è¦æ±‚è¾ƒé«˜çš„åœºæ™¯"
                else:
                    impact_level = "è¾ƒé«˜å½±å“"
                    recommendation = "é€‚åˆå¯¹æ¼æŠ¥æå…¶æ•æ„Ÿçš„åœºæ™¯"
                
                f.write(f"   ä¸šåŠ¡å½±å“: {impact_level}\n")
                f.write(f"   åº”ç”¨å»ºè®®: {recommendation}\n")
            
            # é»˜è®¤é˜ˆå€¼å¯¹æ¯”
            f.write(f"\n\nğŸ” é»˜è®¤é˜ˆå€¼(0.5)å¯¹æ¯”åˆ†æ:\n")
            f.write("-" * 50 + "\n")
            
            # æ‰¾åˆ°æœ€æ¥è¿‘0.5çš„é˜ˆå€¼ç»“æœ
            default_threshold = 0.5
            closest_to_default = min(results_df.iterrows(), key=lambda x: abs(x[1]['threshold'] - default_threshold))
            default_metrics = closest_to_default[1]
            
            f.write(f"é»˜è®¤é˜ˆå€¼æ€§èƒ½:\n")
            f.write(f"  é˜ˆå€¼: {default_metrics['threshold']:.3f}\n")
            f.write(f"  ç²¾ç¡®ç‡: {default_metrics['precision']:.4f}\n")
            f.write(f"  å¬å›ç‡: {default_metrics['recall']:.4f}\n")
            f.write(f"  F1åˆ†æ•°: {default_metrics['f1']:.4f}\n")
            f.write(f"  è¯¯æŠ¥ç‡: {default_metrics['fpr']:.4f} ({default_metrics['fpr']*100:.2f}%)\n")
            f.write(f"  è¯¯æŠ¥æ ·æœ¬: {int(default_metrics['fp'])}\n\n")
            
            # ä¸æœ€ä¼˜ç­–ç•¥å¯¹æ¯”
            best_fpr_strategy = strategies_by_fpr[0]
            best_metrics = best_fpr_strategy[1]
            
            f.write(f"æœ€ä¼˜ä½è¯¯æŠ¥ç­–ç•¥ ({best_fpr_strategy[0]}):\n")
            f.write(f"  é˜ˆå€¼: {best_metrics['threshold']:.6f}\n")
            f.write(f"  ç²¾ç¡®ç‡: {best_metrics['precision']:.4f}\n")
            f.write(f"  å¬å›ç‡: {best_metrics['recall']:.4f}\n")
            f.write(f"  F1åˆ†æ•°: {best_metrics['f1']:.4f}\n")
            f.write(f"  è¯¯æŠ¥ç‡: {best_metrics.get('fpr', 0):.6f} ({best_metrics.get('fpr', 0)*100:.4f}%)\n")
            f.write(f"  è¯¯æŠ¥æ ·æœ¬: {int(best_metrics.get('fp', 0))}\n\n")
            
            # æ”¹è¿›æ•ˆæœ
            fp_reduction = int(default_metrics['fp']) - int(best_metrics.get('fp', 0))
            fpr_reduction = default_metrics['fpr'] - best_metrics.get('fpr', 0)
            
            f.write(f"æ”¹è¿›æ•ˆæœ:\n")
            f.write(f"  è¯¯æŠ¥æ ·æœ¬å‡å°‘: {fp_reduction} ä¸ª\n")
            f.write(f"  è¯¯æŠ¥ç‡é™ä½: {fpr_reduction:.6f} ({fpr_reduction*100:.4f} ä¸ªç™¾åˆ†ç‚¹)\n")
            if default_metrics['fp'] > 0:
                relative_reduction = (fp_reduction / default_metrics['fp']) * 100
                f.write(f"  è¯¯æŠ¥ç‡ç›¸å¯¹é™ä½: {relative_reduction:.2f}%\n")
            
            # å®æ–½å»ºè®®
            f.write(f"\n\nğŸ’¡ å®æ–½å»ºè®®:\n")
            f.write("-" * 30 + "\n")
            f.write("1. æ ¹æ®ä¸šåŠ¡å¯¹è¯¯æŠ¥çš„å®¹å¿åº¦é€‰æ‹©ç›¸åº”ç­–ç•¥:\n")
            f.write("   - é‡‘è/åŒ»ç–—ç­‰å…³é”®é¢†åŸŸ: é€‰æ‹©æä¸¥æ ¼è¯¯æŠ¥æ§åˆ¶ç­–ç•¥\n")
            f.write("   - ä¸€èˆ¬ä¸šåŠ¡åº”ç”¨: é€‰æ‹©å¹³è¡¡ç­–ç•¥\n")
            f.write("   - ç›‘æ§å‘Šè­¦ç³»ç»Ÿ: å¯è€ƒè™‘é€‚åº¦æ”¾å®½è¯¯æŠ¥æ§åˆ¶\n\n")
            f.write("2. é˜¶æ®µæ€§éƒ¨ç½²å»ºè®®:\n")
            f.write("   - ç¬¬ä¸€é˜¶æ®µ: ä½¿ç”¨è¾ƒä¸¥æ ¼ç­–ç•¥(å¦‚Ultra Low FPR)è¿›è¡Œå°æµé‡æµ‹è¯•\n")
            f.write("   - ç¬¬äºŒé˜¶æ®µ: æ ¹æ®å®é™…æ•ˆæœè°ƒæ•´åˆ°åˆé€‚çš„å¹³è¡¡ç‚¹\n")
            f.write("   - ç¬¬ä¸‰é˜¶æ®µ: å»ºç«‹åŠ¨æ€é˜ˆå€¼è°ƒæ•´æœºåˆ¶\n\n")
            f.write("3. ç›‘æ§æŒ‡æ ‡:\n")
            f.write("   - æŒç»­ç›‘æ§è¯¯æŠ¥ç‡å’Œæ¼æŠ¥ç‡å˜åŒ–\n")
            f.write("   - å®šæœŸé‡æ–°è¯„ä¼°é˜ˆå€¼æœ‰æ•ˆæ€§\n")
            f.write("   - å»ºç«‹å¼‚å¸¸é˜ˆå€¼å˜åŒ–çš„å‘Šè­¦æœºåˆ¶\n")
        
        print(f"ğŸ“ é«˜çº§é˜ˆå€¼åˆ†ææŠ¥å‘Šå·²ä¿å­˜ä¸º: output/advanced_threshold_analysis.txt")
except Exception as e:
    print(f"âš ï¸  å†³ç­–æ ‘è§„åˆ™ä¿å­˜å¤±è´¥: {e}")

# 16. æ€»ç»“æŠ¥å‘Š
print(f"\n1ï¸âƒ£6ï¸âƒ£ å†³ç­–æ ‘åˆ†ç±»ä»»åŠ¡æ€»ç»“æŠ¥å‘Š")
print("=" * 60)
print(f"ğŸ¯ ä»»åŠ¡: PCDNæµé‡ä¸æ­£å¸¸æµé‡äºŒåˆ†ç±»")
print(f"ğŸŒ³ æ¨¡å‹: Decision Tree Classifier")
print(f"ğŸ”§ ä½¿ç”¨ç‰¹å¾: {', '.join(selected_features)}")
print(f"ğŸ“Š æ•°æ®è§„æ¨¡:")
print(f"  è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬")
print(f"  éªŒè¯é›†: {len(X_val)} æ ·æœ¬") 
print(f"  æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬")

print(f"\nğŸ† æœ€ç»ˆæ€§èƒ½æŒ‡æ ‡:")
print(f"  æµ‹è¯•é›†å‡†ç¡®ç‡: {test_acc:.4f} ({test_acc*100:.2f}%)")
print(f"  æµ‹è¯•é›†AUCå€¼: {test_auc:.4f}")

print(f"\nğŸŒ³ å†³ç­–æ ‘æ¨¡å‹å‚æ•°:")
for param, value in grid_search.best_params_.items():
    print(f"  {param}: {value}")

print(f"\nğŸŒ³ å†³ç­–æ ‘ç»“æ„:")
print(f"  æ ‘çš„æ·±åº¦: {dt_model.get_depth()}")
print(f"  å¶å­èŠ‚ç‚¹æ•°: {dt_model.get_n_leaves()}")
print(f"  æ€»èŠ‚ç‚¹æ•°: {dt_model.tree_.node_count}")

print(f"\nğŸ“ˆ ç‰¹å¾é‡è¦æ€§:")
for idx, row in importance_df.iterrows():
    percentage = (row['importance'] / importance_df['importance'].sum()) * 100
    print(f"  {row['feature']}: {row['importance']:.4f} ({percentage:.1f}%)")

print(f"\nğŸ¯ é«˜çº§é˜ˆå€¼ä¼˜åŒ–ç»“æœ:")
if test_strategies:
    print(f"  å…±å‘ç° {len(test_strategies)} ç§ä¼˜åŒ–ç­–ç•¥")
    
    # æ˜¾ç¤ºæœ€ä½³çš„å‡ ä¸ªä½è¯¯æŠ¥ç­–ç•¥
    strategies_by_fpr = sorted(test_strategies.items(), key=lambda x: x[1].get('fpr', 1.0))
    print(f"  ğŸ† æ¨èä½è¯¯æŠ¥ç­–ç•¥:")
    
    for i, (strategy_name, metrics) in enumerate(strategies_by_fpr[:3], 1):
        fpr_pct = metrics.get('fpr', 0) * 100
        fp_samples = int(metrics.get('fp', 0))
        print(f"    {i}. {strategy_name}")
        print(f"       é˜ˆå€¼: {metrics['threshold']:.4f} | è¯¯æŠ¥ç‡: {fpr_pct:.3f}% | è¯¯æŠ¥æ ·æœ¬: {fp_samples}")
        print(f"       ç²¾ç¡®ç‡: {metrics['precision']:.3f} | å¬å›ç‡: {metrics['recall']:.3f} | F1: {metrics['f1']:.3f}")

print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
print(f"  å†³ç­–æ ‘å¯è§†åŒ–: output/decision_tree_single_clear.png")
print(f"  æ€§èƒ½åˆ†æå›¾: output/decision_tree_performance_analysis.png")
print(f"  é˜ˆå€¼ä¼˜åŒ–åˆ†æå›¾: output/threshold_optimization_analysis.png")
print(f"  å†³ç­–è§„åˆ™æ–‡ä»¶: output/decision_tree_rules.txt")
print(f"  é˜ˆå€¼ä¼˜åŒ–æŠ¥å‘Š: output/threshold_optimization_report.txt")
print(f"  é«˜çº§é˜ˆå€¼åˆ†ææŠ¥å‘Š: output/advanced_threshold_analysis.txt")

print(f"\nğŸ’¡ é˜ˆå€¼ä¼˜åŒ–ä½¿ç”¨å»ºè®®:")
print("=" * 50)
if test_strategies:
    strategies_by_fpr = sorted(test_strategies.items(), key=lambda x: x[1].get('fpr', 1.0))
    
    print(f"ğŸ”´ æä¸¥æ ¼è¯¯æŠ¥æ§åˆ¶åœºæ™¯ (é‡‘èã€åŒ»ç–—ã€å®‰å…¨ç­‰å…³é”®ä¸šåŠ¡):")
    extreme_strategies = [s for s in strategies_by_fpr if s[1].get('fpr', 1) <= 0.005]
    if extreme_strategies:
        best_extreme = extreme_strategies[0]
        print(f"   æ¨èç­–ç•¥: {best_extreme[0]}")
        print(f"   æ¨èé˜ˆå€¼: {best_extreme[1]['threshold']:.4f}")
        print(f"   è¯¯æŠ¥ç‡: {best_extreme[1].get('fpr', 0)*100:.3f}% (çº¦{int(best_extreme[1].get('fp', 0))}ä¸ªè¯¯æŠ¥æ ·æœ¬)")
    
    print(f"\nğŸŸ¡ ä¸€èˆ¬ä¸šåŠ¡åœºæ™¯ (å¹³è¡¡ç²¾ç¡®ç‡å’Œå¬å›ç‡):")
    balanced_strategies = [s for s in strategies_by_fpr if 0.01 <= s[1].get('fpr', 1) <= 0.05]
    if balanced_strategies:
        best_balanced = balanced_strategies[0] if balanced_strategies else strategies_by_fpr[len(strategies_by_fpr)//2]
        print(f"   æ¨èç­–ç•¥: {best_balanced[0]}")
        print(f"   æ¨èé˜ˆå€¼: {best_balanced[1]['threshold']:.4f}")
        print(f"   è¯¯æŠ¥ç‡: {best_balanced[1].get('fpr', 0)*100:.2f}% | F1åˆ†æ•°: {best_balanced[1]['f1']:.3f}")
    
    print(f"\nğŸŸ¢ ç›‘æ§é¢„è­¦åœºæ™¯ (ä¼˜å…ˆä¿è¯æ£€æµ‹ç‡):")
    recall_priority = [s for s in test_strategies.items() if s[1]['recall'] >= 0.9]
    if recall_priority:
        best_recall = max(recall_priority, key=lambda x: x[1]['f1'])
        print(f"   æ¨èç­–ç•¥: {best_recall[0]}")
        print(f"   æ¨èé˜ˆå€¼: {best_recall[1]['threshold']:.4f}")
        print(f"   å¬å›ç‡: {best_recall[1]['recall']:.3f} | ç²¾ç¡®ç‡: {best_recall[1]['precision']:.3f}")

print(f"\nğŸš€ éƒ¨ç½²å®æ–½æ­¥éª¤:")
print(f"  1ï¸âƒ£ ç¦»çº¿éªŒè¯: ä½¿ç”¨å†å²æ•°æ®éªŒè¯é€‰å®šé˜ˆå€¼çš„æ•ˆæœ")
print(f"  2ï¸âƒ£ ç°åº¦æµ‹è¯•: å…ˆåœ¨å°æ¯”ä¾‹æµé‡ä¸Šæµ‹è¯•æ–°é˜ˆå€¼")
print(f"  3ï¸âƒ£ æ•ˆæœç›‘æ§: å®æ—¶ç›‘æ§è¯¯æŠ¥ç‡ã€æ¼æŠ¥ç‡å˜åŒ–")
print(f"  4ï¸âƒ£ åŠ¨æ€è°ƒæ•´: æ ¹æ®ä¸šåŠ¡åé¦ˆå’Œæ•°æ®å˜åŒ–è°ƒæ•´é˜ˆå€¼")
print(f"  5ï¸âƒ£ å®šæœŸè¯„ä¼°: æ¯æœˆé‡æ–°è¯„ä¼°é˜ˆå€¼çš„æœ‰æ•ˆæ€§")

print(f"\nğŸ“Š ç›‘æ§æŒ‡æ ‡å»ºè®®:")
print(f"  â€¢ æ ¸å¿ƒæŒ‡æ ‡: è¯¯æŠ¥ç‡ (FPR) < ä¸šåŠ¡å®¹å¿é˜ˆå€¼")
print(f"  â€¢ å¹³è¡¡æŒ‡æ ‡: F1åˆ†æ•°ä¿æŒåœ¨åˆç†èŒƒå›´")
print(f"  â€¢ ä¸šåŠ¡æŒ‡æ ‡: äººå·¥å®¡æ ¸å·¥ä½œé‡ã€ç”¨æˆ·æŠ•è¯‰ç‡")
print(f"  â€¢ ç³»ç»ŸæŒ‡æ ‡: æ¨¡å‹é¢„æµ‹å»¶è¿Ÿã€ç³»ç»Ÿèµ„æºæ¶ˆè€—")

print(f"\nâœ… é«˜çº§é˜ˆå€¼ä¼˜åŒ–åˆ†æå®Œæˆ!")
print(f"ğŸ‰ æ€»å…±æµ‹è¯•äº†999ä¸ªé˜ˆå€¼ç‚¹ï¼Œç”Ÿæˆäº†{len(test_strategies)}ç§ä¼˜åŒ–ç­–ç•¥!")
print("=" * 60)